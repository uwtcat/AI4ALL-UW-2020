{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice Problems - Lesson 9_Naive Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rl57sDm6om2n"
      },
      "source": [
        "# Practice Problems\n",
        "## Lesson 9: Proability and Naive Bayes\n",
        "---\n",
        "Created for AI4ALL UW 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdJ2RYfa6J6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from future.utils import iteritems"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qz4bc5YuotbW"
      },
      "source": [
        "### Problem 1 - Probability\n",
        "\n",
        "Suppose we have two bags containing four types of gems: diamond, garnet, amethyst, and pearl (which may ring a bell for any [Steven Universe](https://en.wikipedia.org/wiki/Steven_Universe) fans). We'll call these Bag A and Bag B. The event of randomly selecting a diamond from either bag is denoted with a capital D. The same goes for G for garnet, A for amethyst, and P for Pearl.\n",
        "\n",
        "> Each bag contains the following number of each gem:\n",
        "\n",
        "| Bag A | Bag B |\n",
        "|------------|------------------|\n",
        "| 2 diamonds | 0 diamonds |\n",
        "| 4 garnets | 6 garnets |\n",
        "| 1 amethyst | 3 amethysts |\n",
        "| 0 pearls | 2 pearls |\n",
        "\n",
        "> **For each of the following questions, be sure to answer using the proper notation for probabilities.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nvR5FXX_tc9p"
      },
      "source": [
        "> a. What is the sample space of these bags? (i.e. all possible outcomes if you try to pick something from a bag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YFG7wb4nuhFA"
      },
      "source": [
        "> b. What is the probability of drawing a diamond from Bag A? What is the probability of drawing an amethyst from Bag B? What is the probability of drawing an amethyst or a garnet from Bag A?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zsBS1w04vlMR"
      },
      "source": [
        "> c. What is the probability of drawing a garnet from Bag A and drawing a pearl from Bag B? Are these events independent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OZukuYDdwPsk"
      },
      "source": [
        "> d. What is the probability of drawing two diamonds from Bag A? That is, drawing a diamond, then drawing a second diamond without replacing the first? Are these events independent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MvdsFH9x0NH"
      },
      "source": [
        "> e. What are the union and intersection of Bag A and Bag B? Provide an example of an event which produces an empty set of outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bI2vWOhQy0fy"
      },
      "source": [
        "> f. Suppose two gems, one from each bag, have been drawn. What is the probability of one of the two gems being a garnet given that both gems are garnets? What is the probability of both gems being garnets given that one gem is a garnet? *(This is where Bayes' theorem comes in handy!)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j_bxg4xD2TZT"
      },
      "source": [
        "### Problem 2 - Naive Bayes\n",
        "\n",
        "Try building an Naive Bayes Classifier for MNIST dataset. Below is code for one possible way to do this that you can look at if you don't figure this part out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hMYH62jn2_Pq",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "976de450-205c-407c-81b0-19c1e20b954c"
      },
      "source": [
        "import matplotlib.pyplot as plt    # charting library\n",
        "import numpy as np                 # Python array library\n",
        "import pandas as pd                # Pandas dataframe library\n",
        "import joblib                      # for importing and storing classifier libraries\n",
        "from datetime import datetime                    # for timing the build\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from builtins import range, input\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import multivariate_normal as mvn\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "print(X[0])\n",
        "print(y[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
            "  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
            " 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
            " 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
            " 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
            "  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
            "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
            "  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
            " 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
            " 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
            " 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
            " 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
            " 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
            "  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "aRLk6Hcx6J6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bac922b4-a358-4b02-e03a-1f85c30745aa"
      },
      "source": [
        "# Partition the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Using a Gaussian Naive Bayes classifier\n",
        "model = GaussianNB()\n",
        "#model = MultinomialNB()\n",
        "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
        "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0], (y_test != y_pred).sum()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mislabeled points out of a total 17500 points : 7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5lkEMBWD6J61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "305a9094-d7bd-4afb-a1c8-c6b77e3acd76"
      },
      "source": [
        "    t0 = datetime.now()\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Training time:\", (datetime.now() - t0))\n",
        "\n",
        "    t0 = datetime.now()\n",
        "    print(\"\\nTrain accuracy:\", model.score(X_train, y_train))\n",
        "    print(\"Time to compute train accuracy:\", (datetime.now() - t0), \"Train size:\", len(y_train))\n",
        "\n",
        "    t0 = datetime.now()\n",
        "    print(\"\\nTest accuracy:\", model.score(X_test, y_test))\n",
        "    print(\"Time to compute test accuracy:\", (datetime.now() - t0), \"Test size:\", len(y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 0:00:00.627013\n",
            "\n",
            "Train accuracy: 0.5594476190476191\n",
            "Time to compute train accuracy: 0:00:02.199994 Train size: 52500\n",
            "\n",
            "Test accuracy: 0.5635428571428571\n",
            "Time to compute test accuracy: 0:00:00.855409 Test size: 17500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAyGIcqX6J64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}