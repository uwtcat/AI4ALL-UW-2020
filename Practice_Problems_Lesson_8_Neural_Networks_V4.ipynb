{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice Problems Lesson 8 Neural Networks V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LOeLiXAfUc7g"
      },
      "source": [
        "# Practice Problems\n",
        "## Lesson 8: Neural Networks\n",
        "---\n",
        "Created by Terron Ishihara.  Modified for University of Washington, AI4All, 2020\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mggjIxKJUgiZ"
      },
      "source": [
        "## Problem \n",
        "\n",
        "Let's explore neural networks using scikit-learn's Multi-layer Perceptron (basically another name for a neural net). Naturally, we will use the MNIST hand-written digits dataset, which is essentially the \"hello world\" example for neural network classification.\n",
        "\n",
        "> Start by importing the dataset and necessary Python libraries. This may take a little while since the dataset is a little larger than the ones we've used in past problems.  \n",
        "\n",
        "#### You must run this script before running any of the other scripts in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXSQNTytZSi9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d02716dd-a137-4781-c818-a94b40212a6a"
      },
      "source": [
        "import matplotlib.pyplot as plt    # charting library\n",
        "import numpy as np                 # Python array library\n",
        "import pandas as pd                # Pandas dataframe library\n",
        "import joblib                      # for importing and storing classifier libraries\n",
        "import datetime                    # for timing the build\n",
        "\n",
        "# Logic to run this notebook on Google Colab.   Prior to running this notebook,\n",
        "# Create a \"\\neural\" folder under \"\\Colab Notebooks\" and upload all support files up there.\n",
        "# If run from from local Jupyter install, comment out drive commands and make FILEROOT an empty string.\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount(\"/drive\", force_remount=True)\n",
        "FILEROOT = \"/drive/My Drive/Colab Notebooks/neural/\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "X = X / X.max()\n",
        "\n",
        "# Partition the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tixhW2hudJSV"
      },
      "source": [
        "### Image display functions\n",
        "\n",
        "> display_array_as_image takes an 784 grey scale values as dissplays them as a grid.  Each data point is a 28x28 matrix of grayscale values between 0 and 1. Let's visualize this by plotting these values. Feel free to change the index into X to see what other digits are in the dataset.\n",
        "\n",
        "> convert_image_to__grey_list takes a 28 * 28 jpg, png, or gif file and converts it to a Python list of 784 greyscale values with a dark background.  Feel free to create your own 28 * 28 jpg, png, or gif file and see how it works. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kscoX5K2qfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "19f75bc3-e856-46b9-a994-75b46134b7d4"
      },
      "source": [
        "def display_array_as_image(image_array):\n",
        "    plt.gray() \n",
        "    # Since each data point is stored in a list of 784 values, we have\n",
        "    # to reshape the list into a 28x28 array.\n",
        "    digit = image_array.reshape(28,28)\n",
        "    plt.matshow(digit)\n",
        "    plt.show()\n",
        "    \n",
        "def convert_image_to_grey_list(filename):\n",
        "    \n",
        "    digitpic = plt.imread(filename)\n",
        "    # check if image is the correct size\n",
        "    if (len(digitpic) != 28 or len(digitpic[0]) != 28):\n",
        "        raise ValueError(\"Image must be 28  * 28\")\n",
        "        \n",
        "    digitpic = digitpic/digitpic.max()\n",
        "    piclist = []\n",
        "    for i in range(28):          # hardcoding lengths since must be 28 * 28 \n",
        "        for j in range(28):\n",
        "            pixel = digitpic[i][j]\n",
        "            piclist.append((pixel[0]+pixel[1]+pixel[2])/3)\n",
        "            \n",
        "    if (sum(piclist) / len(piclist) > 0.5):   # if image is dark on light, then switch\n",
        "            for i in range(len(piclist)):\n",
        "                piclist[i] = 1 - piclist[i]\n",
        "        \n",
        "    return piclist \n",
        "  \n",
        "# Test these functions   \n",
        "display_array_as_image(X[0])                   # takes one of the training images and displays\n",
        "testImg = np.array(convert_image_to_grey_list(FILEROOT + \"test3.png\"))   # takes a file and converts it to a 784 greyscale list\n",
        "display_array_as_image(testImg)                # display greyscale array"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06EoDvQJ2qfM",
        "colab_type": "text"
      },
      "source": [
        "### Loading an MLP Model and displaying its accuracy\n",
        "\n",
        "> The following code loads an already created model into the variable joblib_model. The model file is in the same folder as the Jupyter notebook.  Please see folder for other models you can load. \n",
        "> After loading the model, the predicted values for both the training set and test set are calculated and stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQENI6al2qfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "689b1030-3d9a-4d84-8966-56b659802856"
      },
      "source": [
        "# Load from file\n",
        "mnist_file = \"mnist_model_0708.pkl\"\n",
        "joblib_model = joblib.load(FILEROOT + mnist_file)\n",
        "\n",
        "# calculate predicted values for both training data and test date\n",
        "print (datetime.datetime.now())\n",
        "y_train_predict = joblib_model.predict(X_train)\n",
        "y_test_predict = joblib_model.predict(X_test)\n",
        "\n",
        "# display how accurate model is on test data\n",
        "score = joblib_model.score(X_test, y_test)\n",
        "print (score)\n",
        "print (datetime.datetime.now())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-28 03:59:12.097622\n",
            "0.9932571428571428\n",
            "2020-07-28 03:59:13.217852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9-jfnA92qfP",
        "colab_type": "text"
      },
      "source": [
        "### Display how loaded MLP Model predicts a particular image\n",
        "\n",
        "> Using the functions described above, the following code shows to display either a file or a particular training or test image and and then show the prediction made by the model for that image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8etoO6a2qfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "63f658c5-2a1d-4cb7-8aa8-3adb4f787f92"
      },
      "source": [
        "\n",
        "testImg = np.array(convert_image_to_grey_list(FILEROOT + \"test.jpg\"))   # takes a file and converts it to a 784 greyscale list\n",
        "display_array_as_image(testImg) \n",
        "print (joblib_model.predict(np.reshape(testImg,(-1,784)))) #print out prediction after converting image to format required by model\n",
        "\n",
        "\n",
        "testImg = X[5]                                           # takes either a training or test image\n",
        "display_array_as_image(testImg)\n",
        "print (joblib_model.predict(np.reshape(testImg,(-1,784)))) #print out prediction after converting image to format required by model\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['9']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSby9tt12qfU",
        "colab_type": "text"
      },
      "source": [
        "### Analyzing Accuracy Results (Step 1: Dataframe Creation)\n",
        "\n",
        "> The following code shows how to create a dataframe that maps the actual values of the test set vs the predicted values for further analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnhpxD4P2qfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_results = pd.DataFrame(columns=(\"actual\",\"predict\",\"count\"))\n",
        "test_results[\"actual\"] = y_test\n",
        "test_results[\"predict\"] = y_test_predict\n",
        "test_results[\"count\"] = 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRAnF0_M2qfY",
        "colab_type": "text"
      },
      "source": [
        "### Analyzing Accuracy Results (Step 2: Analyze Accuracy by Cluster)\n",
        "> The following code shows how to create a dataframe that shows the number of times the model gets each actual number correct/incorrect and the correct percentage for each actual number.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZAocnDI2qfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "77094f77-f668-4607-d796-a566ca6b8919"
      },
      "source": [
        "# Shows how well each digit is analyzed\n",
        "clf_byclass = pd.DataFrame(columns=(\"actual\",\"correct\",\"incorrect\"))\n",
        "clf_byclass[\"actual\"] = range(10)\n",
        "clf_byclass[\"correct\"] = 0\n",
        "clf_byclass[\"incorrect\"] = 0\n",
        "clf_byclass.set_index(\"actual\")\n",
        "\n",
        "for row in test_results.itertuples():\n",
        "    r1 = int(row[1])\n",
        "    r2 = int(row[2])\n",
        "    if r1 == r2:\n",
        "        clf_byclass.loc[r1,\"correct\"] = clf_byclass.loc[r1,\"correct\"] + 1\n",
        "    else:\n",
        "         clf_byclass.loc[r1,\"incorrect\"] =  clf_byclass.loc[r1,\"incorrect\"] + 1\n",
        " \n",
        "  \n",
        "clf_byclass[\"pct\"] = clf_byclass[\"correct\"] / (clf_byclass[\"correct\"] + clf_byclass[\"incorrect\"])\n",
        "clf_byclass"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>correct</th>\n",
              "      <th>incorrect</th>\n",
              "      <th>pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1726</td>\n",
              "      <td>9</td>\n",
              "      <td>0.994813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1999</td>\n",
              "      <td>10</td>\n",
              "      <td>0.995022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1738</td>\n",
              "      <td>14</td>\n",
              "      <td>0.992009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1713</td>\n",
              "      <td>19</td>\n",
              "      <td>0.989030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1642</td>\n",
              "      <td>10</td>\n",
              "      <td>0.993947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1589</td>\n",
              "      <td>7</td>\n",
              "      <td>0.995614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1746</td>\n",
              "      <td>7</td>\n",
              "      <td>0.996007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1860</td>\n",
              "      <td>15</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1676</td>\n",
              "      <td>15</td>\n",
              "      <td>0.991130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1693</td>\n",
              "      <td>12</td>\n",
              "      <td>0.992962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   actual  correct  incorrect       pct\n",
              "0       0     1726          9  0.994813\n",
              "1       1     1999         10  0.995022\n",
              "2       2     1738         14  0.992009\n",
              "3       3     1713         19  0.989030\n",
              "4       4     1642         10  0.993947\n",
              "5       5     1589          7  0.995614\n",
              "6       6     1746          7  0.996007\n",
              "7       7     1860         15  0.992000\n",
              "8       8     1676         15  0.991130\n",
              "9       9     1693         12  0.992962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc5oJMoG2qfd",
        "colab_type": "text"
      },
      "source": [
        "### Analyzing Accuracy Results (Step 3: Analyze Errors by Cluster)\n",
        "> The following code shows how to create a pivot table that shows the number of errors of each type occured for each actual value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pStpbb72qfe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "c566cea4-31fe-431b-f2d9-1cbbaa99f909"
      },
      "source": [
        "test_error = test_results[test_results[\"predict\"]!=test_results[\"actual\"]]  # get only errors\n",
        "test_error_pivot = pd.pivot_table(test_error, values=['count'], index=['actual'],columns=['predict'], aggfunc=np.sum) #create pivot table\n",
        "test_error_pivot"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"10\" halign=\"left\">count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        count                                             \n",
              "predict     0    1    2    3    4    5    6    7    8    9\n",
              "actual                                                    \n",
              "0         NaN  NaN  1.0  1.0  NaN  3.0  2.0  NaN  1.0  1.0\n",
              "1         NaN  NaN  2.0  3.0  2.0  NaN  NaN  2.0  NaN  1.0\n",
              "2         NaN  2.0  NaN  3.0  1.0  1.0  1.0  3.0  3.0  NaN\n",
              "3         1.0  NaN  2.0  NaN  NaN  4.0  1.0  2.0  7.0  2.0\n",
              "4         NaN  1.0  NaN  NaN  NaN  NaN  1.0  1.0  1.0  6.0\n",
              "5         NaN  NaN  1.0  1.0  NaN  NaN  3.0  NaN  2.0  NaN\n",
              "6         1.0  NaN  NaN  NaN  2.0  2.0  NaN  NaN  2.0  NaN\n",
              "7         1.0  1.0  4.0  NaN  2.0  1.0  NaN  NaN  2.0  4.0\n",
              "8         2.0  1.0  2.0  2.0  2.0  1.0  4.0  NaN  NaN  1.0\n",
              "9         1.0  NaN  NaN  2.0  2.0  3.0  NaN  3.0  1.0  NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Lazd03d5ee"
      },
      "source": [
        "### Build Your Own Classifier\n",
        "\n",
        "> After you have investigated how well the classifier may work, you can try initializing and building your own classifier, training it, and observe how well the classifier works on our test set. \n",
        "\n",
        "> The `hidden_layer_sizes` parameter accepts a tuple that specifies the number of hidden layers and the number of neurons per layer. The `solver` parameter specifies that we'll use Stochastic Gradient Descent.\n",
        "\n",
        "> * `hidden_layer_sizes`: The number of hidden layers and number of neurons per layer. For example, the tuple (64, 32, 16) represents 3 hidden layers, with 64, 32, and 16 neurons, respectively.\n",
        "> * `solver`: The solver for weight optimization. We learned about Stochastic Gradient Descent, so we use that here.\n",
        "> * `activation`: The activation function for the hidden layers. Possible values are `'identity'`, `'logistic'`, `'tanh'`, and `'relu'`.\n",
        "> * `max_iter`: The maximum number of iterations (updates) to perform. Ideally, the weights will converge, meaning the updates hardly change the weights. Keeping this value low will prevent the code from taking a long time (but may sacrifice accuracy).\n",
        "\n",
        "> The setup provided below is not very accurate at predicting on the test set. Go ahead and run the code to see the resulting score. \n",
        "\n",
        "> Try changing the parameters for the classifier and see how it affects the score. (`solver` needn't be changed since stochastic gradient descent is the only solver we learned about.) For example, which activation function that we mentioned in the lesson may be very effective?\n",
        "\n",
        "> Note that the code also saves the model created to a file so that it can be further analyzed using the code above.   For each new classifier that you want to save. either change the name of the model file in the code below or change it in the file system after the model has been saved. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "muzgZTffeAEO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1df833fa-c6ca-4740-b950-108b925dc4f6"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Initialize the classifier.   Note that this original attempt did not run\n",
        "# This takes a long time to run but does work\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "mlp_clf = MLPClassifier(\n",
        "    hidden_layer_sizes=(64,32), \n",
        "    solver='sgd', \n",
        "    activation='logistic',\n",
        "    max_iter=100\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "\n",
        "# Save the model file in the current working directory.   Change the file name for each iteration\n",
        "mnist_file = FILEROOT + \"mnist_model_zzzz.pkl\"\n",
        "joblib.dump(mlp_clf, mnist_file)\n",
        "\n",
        "# Get the mean accuracy on the test data and print it\n",
        "score = mlp_clf.score(X_test, y_test)\n",
        "print (score)\n",
        "\n",
        "print (datetime.datetime.now())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-28 03:59:18.607494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-28 04:01:34.751805\n",
            "0.8772\n",
            "2020-07-28 04:01:34.981067\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}