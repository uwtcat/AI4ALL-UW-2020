{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice - KNearest_and_NeuralNet_Compare - V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kh38YnZvzLmv"
      },
      "source": [
        "## Comparing K-Nearest Neighbor Classification with Neural Network Classification\n",
        "---\n",
        "Created by Terron Ishihara, Modified by University of Washington AI4All, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WjhJjdo5CQ7S"
      },
      "source": [
        "### K-Nearest Neighbor Classification with a Larger Dataset\n",
        "\n",
        "Let's first explore building a K-Nearest Neighbors classifier using the same MNIST dataset as was used to build our neural network classifier. In the K-nearest neighbor classification, we used very low-resolution (8x8 pixels) version of the MNIST data set trained with about 1600 images.  The larger dataset used to train the neural network classifier was 7000 28 * 28 pixel images. \n",
        "\n",
        "#### Data and Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxYbmBgKoOXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4e78cea5-6637-458e-b620-37a60ee6dc56"
      },
      "source": [
        "import matplotlib.pyplot as plt    # charting library\n",
        "import numpy as np                 # Python array library\n",
        "import pandas as pd                # Pandas dataframe library\n",
        "import joblib                      # for importing and storing classifier libraries\n",
        "import datetime\n",
        "\n",
        "# Logic to run this notebook on Google Colab.   Prior to running this notebook,\n",
        "# Create a \"\\neural\" folder under \"\\Colab Notebooks\" to write classifier model files to.\n",
        "# If run from from local Jupyter install, comment out drive commands and make FILEROOT an empty string.\n",
        " \n",
        "from google.colab import drive\n",
        "drive.mount(\"/drive\", force_remount=True)\n",
        "FILEROOT = \"/drive/My Drive/Colab Notebooks/neural/\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn import datasets, neighbors\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "X = X / X.max()\n",
        "\n",
        "# Partition the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "print (len(X))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n",
            "2020-07-28 04:55:15.764468\n",
            "2020-07-28 04:55:36.642545\n",
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jFewwIymPZRj"
      },
      "source": [
        "### Training and Testing the K-Nearest Neighbor with a Larger Dataset\n",
        "\n",
        "> All that's left is to import the K-Nearest Neighbors classifier, train the classifier on the training set, and test the resulting model on the test set. \n",
        "\n",
        "> If you actually run this you will find that although buiding/training the classifer with the larger dataset is very quick, running tests is actually very slow. \n",
        "\n",
        "#### Warning: Computing accuracy with this model is slow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMGdfpQSIvIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a351ed8a-945b-449e-aeaf-b6ca2de13550"
      },
      "source": [
        "# Import the default K-Nearest Neighbors classifier\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the classifer\n",
        "knn.fit(X_train, y_train)\n",
        "print (datetime.datetime.now())\n",
        "\n",
        "mnist_file = FILEROOT + \"mnist_kmeans_model_KNKN.pkl\"\n",
        "joblib.dump(knn, mnist_file)\n",
        "\n",
        "# Compute the score (mean accuracy) on test set\n",
        "score = knn.score(X_test, y_test)\n",
        "print('KNN score: %f' % score)\n",
        "print (datetime.datetime.now())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-28 04:55:36.656042\n",
            "2020-07-28 04:55:49.377482\n",
            "KNN score: 0.968229\n",
            "2020-07-28 05:21:44.020134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w9YlRHE-nid6"
      },
      "source": [
        "### Neural Network Classification with a Smaller Dataset\n",
        "\n",
        "Next let's explore building a Neural Network classifier using the same smaller MNIST dataset as was used to build the K-nearest neighbor classifier a few lessons ago. In the K-nearest neighbor classification, we used very low-resolution (8x8 pixels) version of the MNIST data set trained with about 1600 images.  The larger dataset used to train the neural network classifier was 7000 28 * 28 pixel images. \n",
        "\n",
        "#### Data Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52edY71EoOXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the digits data set\n",
        "digits = datasets.load_digits() \n",
        "\n",
        "# Extract the input data, force values to be between 0.0 and 1.0\n",
        "X_digits = digits.data / digits.data.max()\n",
        "\n",
        "# Extract the true values for each sample (each a digit between 0-9)\n",
        "y_digits = digits.target\n",
        "\n",
        "# Partition the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0nASIeoOXP",
        "colab_type": "text"
      },
      "source": [
        "#### Training and Testing the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOhVmhImoOXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "75a3c273-e82d-48c9-b095-ff816d20122d"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Initialize the classifier.   You will need to play with the parameters to get the best results\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "mlp_clf = MLPClassifier(\n",
        "    hidden_layer_sizes=(98,32), \n",
        "    solver='sgd', \n",
        "    activation='relu',\n",
        "    max_iter=1000\n",
        ")\n",
        "\n",
        "# Train the classifier\n",
        "mlp_clf.fit(X_train, y_train)\n",
        "\n",
        "print (datetime.datetime.now())\n",
        "\n",
        "# Save the model file in the current working directory.   Change the file name for each iteration\n",
        "mnist_file = FILEROOT + \"mnist_model_SNSN.pkl\"\n",
        "joblib.dump(mlp_clf, mnist_file)\n",
        "\n",
        "# Get the mean accuracy on the test data and print it\n",
        "score = mlp_clf.score(X_test, y_test)\n",
        "print (score)\n",
        "\n",
        "print (datetime.datetime.now())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-28 05:21:44.148166\n",
            "2020-07-28 05:21:58.451959\n",
            "0.9644444444444444\n",
            "2020-07-28 05:21:58.507248\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}